{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetic.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from medpy.io import load\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "import scipy\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.misc import imread\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rootDir = \"/home/ubuntu/Yang_Sahana/train\"\n",
    "ls_file = []\n",
    "for root, dirs, files in os.walk(rootDir):\n",
    "    for fileName in files:\n",
    "        if fileName.endswith('.jpeg'):\n",
    "            ls_file.append(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ls_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1 = mpimg.imread('sample/' + ls_file[0])\n",
    "img2 = mpimg.imread('sample/' + ls_file[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1.nbytes / 10**6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.resize(img1, (512, 512)).nbytes / 10**6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "width = img1.shape[0]\n",
    "height = img1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = width/2\n",
    "y = height/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img1[:,500:4000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CroppedImagev1(filename, CropRectangle = True):\n",
    "    img = mpimg.imread(filename)\n",
    "    height, width, channels = img.shape\n",
    "    if CropRectangle:\n",
    "        if width > height:\n",
    "            delta = width - height\n",
    "            left = int(delta/2)\n",
    "            upper = 0\n",
    "            right = height + left\n",
    "            lower = height\n",
    "        else:\n",
    "            delta = height - width\n",
    "            left = 0\n",
    "            upper = int(delta/2)\n",
    "            right = width\n",
    "            lower = width + upper\n",
    "        img = img[upper:lower, left:right]\n",
    "    plt.imshow(img)\n",
    "    print \"final height, width\", img.shape\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgb_added = img.sum(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(rgb_added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_added.max() / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(rgb_added.sum(axis=0), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img.sum(axis=2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img.sum(axis=2).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.mean(rgb_added.mean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgb_added.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(rgb_added.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "std = np.std(rgb_added.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(286-193)*3888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(rgb_added.sum(axis=0) < (286-193)*3888*.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = imread('sample/16_left.jpeg')\n",
    "img_128 = cv2.resize(img, (128,128))\n",
    "plt.imshow(img)\n",
    "plt.axvline(340)\n",
    "plt.axvline(3579)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_borders(img_path, threshold=0.01):\n",
    "    img = imread(img_path)\n",
    "\n",
    "    rgb_added = img.sum(axis=2)\n",
    "    mean_px = rgb_added.mean()\n",
    "    std_px = rgb_added.std()\n",
    "    # not using std as it can be very high\n",
    "\n",
    "    col_sum = rgb_added.sum(axis=0)\n",
    "    row_sum = rgb_added.sum(axis=1)\n",
    "\n",
    "    thresh_val = (mean_px)*threshold\n",
    "    col_index = np.where(col_sum > thresh_val*col_sum.shape[0])\n",
    "    row_index = np.where(row_sum > thresh_val*row_sum.shape[0])\n",
    "    hstart, hend = col_index[0][0], col_index[0][-1]\n",
    "    wstart, wend = row_index[0][0], row_index[0][-1]\n",
    "    return img[wstart:wend, hstart:hend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_imgs = filter(lambda x: '.jpeg' in x, os.listdir('sample/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_imgs_path = map(lambda x: 'sample/' + x, sample_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=10, figsize=(50, 50))\n",
    "ax = ax.ravel()\n",
    "for idx in range(10):\n",
    "    ax[idx].imshow(imread(sample_imgs_path[idx]))\n",
    "    ax[idx].set_xticks([])\n",
    "    ax[idx].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=10, figsize=(50, 50))\n",
    "ax = ax.ravel()\n",
    "for idx in range(10):\n",
    "    ax[idx].imshow(crop_borders(sample_imgs_path[idx]))\n",
    "    ax[idx].set_xticks([])\n",
    "    ax[idx].set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = imread('sample/10_left.jpeg')\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "ax = ax.ravel()\n",
    "ax[0].imshow(img)\n",
    "ax[0].axvline(0)\n",
    "ax[1].imshow(crop_borders('sample/10_left.jpeg', 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img[wstart:wend, hstart:hend])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in col_index:\n",
    "    print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resize_128_dir = \"/home/ubuntu/final_data/train/128\"\n",
    "# Create directory for 128x128 resize\n",
    "try:\n",
    "    os.stat(resize_128_dir)\n",
    "except:\n",
    "    os.makedirs(resize_128_dir)\n",
    "    \n",
    "resize_256_dir = \"/home/ubuntu/final_data/train/256\"\n",
    "# Create directory for 256x256 resize\n",
    "try:\n",
    "    os.stat(resize_256_dir)\n",
    "except:\n",
    "    os.makedirs(resize_256_dir)\n",
    "\n",
    "resize_512_dir = \"/home/ubuntu/final_data/train/512\"\n",
    "# Create directory for 512x512 resize\n",
    "try:\n",
    "    os.stat(resize_512_dir)\n",
    "except:\n",
    "    os.makedirs(resize_512_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating .data files\n",
    "\n",
    "# Check if all the files are jpeg format\n",
    "# if not, skip it\n",
    "# else, apply crop border function on it\n",
    "# when you convert to .data, the .jpeg is till there in the filename\n",
    "# therefore, replace the .jpeg with ''\n",
    "\n",
    "for root, dirs, files in os.walk(rootDir):\n",
    "    for fileName in files:\n",
    "        if not fileName.endswith('.jpeg'):\n",
    "            continue\n",
    "        img = crop_borders(rootDir + '/' + fileName)\n",
    "        fileName = fileName.replace(\".jpeg\", \"\")\n",
    "        img_256 = cv2.resize(img, (256,256))\n",
    "        img_256.tofile(resize_256_dir + '/' + fileName + '.data', sep=\"\", format='uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating .data files\n",
    "\n",
    "# Check if all the files are jpeg format\n",
    "# if not, skip it\n",
    "# else, apply crop border function on it\n",
    "# when you convert to .data, the .jpeg is till there in the filename\n",
    "# therefore, replace the .jpeg with ''\n",
    "\n",
    "for root, dirs, files in os.walk(rootDir):\n",
    "    for fileName in files:\n",
    "        if not fileName.endswith('.jpeg'):\n",
    "            continue\n",
    "        img = crop_borders(rootDir + '/' + fileName)\n",
    "        fileName = fileName.replace(\".jpeg\", \"\")\n",
    "        img_512 = cv2.resize(img, (512,512))\n",
    "        img_512.tofile(resize_512_dir + '/' + fileName + '.data', sep=\"\", format='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating .data files\n",
    "\n",
    "# Check if all the files are jpeg format\n",
    "# if not, skip it\n",
    "# else, apply crop border function on it\n",
    "# when you convert to .data, the .jpeg is till there in the filename\n",
    "# therefore, replace the .jpeg with ''\n",
    "\n",
    "for root, dirs, files in os.walk(rootDir):\n",
    "    for fileName in files:\n",
    "        if not fileName.endswith('.jpeg'):\n",
    "            continue\n",
    "        img = crop_borders(rootDir + '/' + fileName)\n",
    "        fileName = fileName.replace(\".jpeg\", \"\")\n",
    "        img_128 = cv2.resize(img, (128,128))\n",
    "        img_128.tofile(resize_128_dir + '/' + fileName + '.data', sep=\"\", format='uint8') # write it out as binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15_right</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16_left</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16_right</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17_right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1\n",
       "5  15_right      2\n",
       "6   16_left      4\n",
       "7  16_right      4\n",
       "8   17_left      0\n",
       "9  17_right      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the labels\n",
    "labels = pd.read_csv('/home/ubuntu/data/trainLabels.csv')\n",
    "labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2b68d7dd90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFfCAYAAAAS+IXqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nC0mS1Mz/B2A4jSJ0gnj3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2b68d7a250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# class imbalance\n",
    "labels['level'].value_counts().plot(kind='bar')\n",
    "\n",
    "# Notes:\n",
    "# 5 labels present - 0 to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1671, 256, 256, 3)\n",
      "(1671, 5)\n",
      "(1122, 256, 256, 3)\n",
      "(1122, 5)\n"
     ]
    }
   ],
   "source": [
    "x_train_list = []\n",
    "y_train_list = []\n",
    "x_val_list = []\n",
    "y_val_list = []\n",
    "\n",
    "train_percent = 0.6 # 60% train\n",
    "Image_File_Path = resize_256_dir # Change this for 128 or 512\n",
    "for index, row in labels.iterrows():\n",
    "    try:\n",
    "        img_data = np.fromfile(Image_File_Path + '/' + row['image'] + '.data', dtype='uint8', sep=\"\")\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    img_data = img_data.reshape([256, 256, 3])\n",
    "    \n",
    "    rand_no = np.random.rand()\n",
    "    if rand_no <= train_percent:\n",
    "        x_list = x_train_list\n",
    "        y_list = y_train_list\n",
    "    else:\n",
    "        x_list = x_val_list\n",
    "        y_list = y_val_list\n",
    "        \n",
    "    if row['level'] == 0:\n",
    "        y_list.append([1, 0, 0, 0, 0])\n",
    "    elif row['level'] == 1:\n",
    "        y_list.append([0, 1, 0, 0, 0])\n",
    "    elif row['level'] == 2:\n",
    "        y_list.append([0, 0, 1, 0, 0])\n",
    "    elif row['level'] == 3:\n",
    "        y_list.append([0, 0, 0, 1, 0])\n",
    "    elif row['level'] == 4:\n",
    "        y_list.append([0, 0, 0, 0, 1])\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    x_list.append(img_data)\n",
    "\n",
    "x_train = np.array(x_train_list)\n",
    "y_train = np.array(y_train_list)\n",
    "print x_train.shape\n",
    "print y_train.shape\n",
    "\n",
    "x_val = np.array(x_val_list)\n",
    "y_val = np.array(y_val_list)\n",
    "print x_val.shape\n",
    "print y_val.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Use_Model = \"VGGNet\" # \"ResNet\" or \"VGGNet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for VGGNet\n",
    "def VGGNet_model(input_shape, num_classes, use_sgd=False):\n",
    "    model_vgg19_conv = VGG19(weights='imagenet', include_top=False)\n",
    "    model_vgg19_conv.summary()\n",
    "    \n",
    "#    for layer in model_vgg16_conv.layers:\n",
    "#        layer.trainable = False\n",
    "\n",
    "    # Create your own input format\n",
    "    input = Input(shape=input_shape, name = 'image_input')\n",
    "    \n",
    "    # Use the generated model \n",
    "    output_vgg19_conv = model_vgg19_conv(input)\n",
    "  \n",
    "    \n",
    "    # Add the fully-connected layers \n",
    "    x = Flatten(name='flatten')(output_vgg19_conv)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(1000, activation='relu', name='fc3')(x)\n",
    "\n",
    "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    # Create model \n",
    "    AD_model = Model(input=input, output=x)\n",
    "    AD_model.summary()\n",
    "\n",
    "    # Compile model\n",
    "    if not use_sgd:\n",
    "        AD_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        print \"using adam optimizer\"\n",
    "    else:\n",
    "        sgd = SGD(lr=0.01, momentum=0.8, decay=0.000001, nesterov=False)\n",
    "        AD_model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[ 'accuracy' ])\n",
    "        print \"using SGD optimizer\"\n",
    "    \n",
    "    return AD_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for resnet\n",
    "def ResNet_model(input_shape, num_classes):\n",
    "    model_resnet_conv = ResNet50(weights='imagenet', include_top=False)\n",
    "    \n",
    "#    for layer in model_vgg16_conv.layers:\n",
    "#        layer.trainable = False\n",
    "\n",
    "    # Create your own input format\n",
    "    input = Input(shape=input_shape, name = 'image_input')\n",
    "    \n",
    "    # Use the generated model \n",
    "    output_resnet_conv = model_resnet_conv(input)\n",
    "    \n",
    "    # Add the fully-connected layers \n",
    "    x = Flatten(name='flatten')(output_resnet_conv)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "\n",
    "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "    \n",
    "    # Create model \n",
    "    AD_model = Model(input=input, output=x)\n",
    "    AD_model.summary()\n",
    "\n",
    "    # Compile model\n",
    "    AD_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return AD_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using VGGNet\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Model)                multiple                  20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 5005      \n",
      "=================================================================\n",
      "Total params: 175,129,525\n",
      "Trainable params: 175,129,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "using SGD optimizer\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "vgg19 (Model)                multiple                  20024384  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              134221824 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 5)                 5005      \n",
      "=================================================================\n",
      "Total params: 175,129,525\n",
      "Trainable params: 175,129,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"pr..., inputs=Tensor(\"im...)`\n"
     ]
    }
   ],
   "source": [
    "if Use_Model == \"ResNet\":\n",
    "    print \"Using ResNet\"\n",
    "    my_model = ResNet_model((256,256,3), 5, use_sgd=True)\n",
    "else:\n",
    "    print \"Using VGGNet\"\n",
    "    my_model= VGGNet_model((256,256,3), 5, use_sgd=True)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1671 samples, validate on 1122 samples\n",
      "Epoch 1/1\n",
      " 250/1671 [===>..........................] - ETA: 3152s - loss: 3.6671 - acc: 0.7536"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "my_model.fit(x_train, y_train, epochs=1, batch_size=50, validation_data=(x_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "#scores = my_model.evaluate(x_test, y_test, verbose=0)\n",
    "#print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
